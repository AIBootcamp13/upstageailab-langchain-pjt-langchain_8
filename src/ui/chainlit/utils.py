# src/ui/chainlit/utils.py

from pathlib import Path

import chainlit as cl

from src.agent import BlogContentAgent
from src.document_preprocessor import DocumentPreprocessor
from src.retriever import RetrieverFactory
from src.ui.enums import SessionKey
from src.vector_store import VectorStore



async def setup_agent(
    llm_provider: str, llm_model: str, force_new_docs: bool = False
) -> BlogContentAgent | None:
    """
    ì—ì´ì „íŠ¸ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ë¬¸ì„œ ì—…ë¡œë“œë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    if force_new_docs or not cl.user_session.get(SessionKey.RETRIEVER):
        files = None
        while files is None:
            files = await cl.AskFileMessage(
                content="ì‹œì‘í•˜ë ¤ë©´ ë¸”ë¡œê·¸ ì´ˆì•ˆì˜ ê¸°ë°˜ì´ ë  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.",
                accept=["application/pdf"],
                max_size_mb=100,
                timeout=300,
                raise_on_timeout=False,
            ).send()

        if not files:
            return None

        file = files[0]
        msg = cl.Message(content=f"`{file.name}` íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
        await msg.send()

        file_path = Path(file.path)
        try:
            preprocessor = DocumentPreprocessor(file_path)
            documents = preprocessor.process()
            cl.user_session.set("processed_documents", documents)
            msg.content = f"âœ… `{file.name}` ì²˜ë¦¬ ì™„ë£Œ: **{len(documents)}ê°œ**ì˜ ì²­í¬ ìƒì„±ë¨."
            await msg.update()

            vector_store = VectorStore()
            vector_store.add_documents(documents)
            cl.user_session.set(SessionKey.VECTOR_STORE, vector_store)
            
            retriever = RetrieverFactory.create(vector_store)
            cl.user_session.set(SessionKey.RETRIEVER, retriever)
        finally:
            pass

        await cl.Message(content="âœ… ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± ì™„ë£Œ! ì—ì´ì „íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.").send()

    retriever = cl.user_session.get(SessionKey.RETRIEVER)
    processed_docs = cl.user_session.get("processed_documents")

    agent = BlogContentAgent(
        retriever=retriever,
        documents=processed_docs,
        llm_provider=llm_provider,
        llm_model=llm_model,
    )
    cl.user_session.set(SessionKey.BLOG_CREATOR_AGENT, agent)
    return agent


async def rebuild_agent_with_new_model(llm_provider: str, llm_model: str) -> None:
    """
    Rebuild or update the BlogContentAgent in the user session when the model/profile changes.
    This will recreate the agent using the existing retriever and processed documents.
    """
    retriever = cl.user_session.get(SessionKey.RETRIEVER)
    processed_docs = cl.user_session.get("processed_documents")

    if not retriever or not processed_docs:
        # If we don't have documents/retriever, prompt user to setup agent flow
        await cl.Message(content="ìƒˆ ëª¨ë¸ì„ ì ìš©í•˜ë ¤ë©´ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.").send()
        return

    agent = BlogContentAgent(
        retriever=retriever,
        documents=processed_docs,
        llm_provider=llm_provider,
        llm_model=llm_model,
    )
    cl.user_session.set(SessionKey.BLOG_CREATOR_AGENT, agent)
    await cl.Message(content=f"âœ… ëª¨ë¸ì´ `{llm_model}`(provider={llm_provider})ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.").send()

    # If we have a session id, regenerate the initial draft with the new model
    session_id = cl.user_session.get(SessionKey.SESSION_ID)
    if session_id:
        # Run generate_draft in thread and stream the result progressively to the UI
        draft = await cl.make_async(agent.generate_draft)(session_id=session_id)
        cl.user_session.set(SessionKey.BLOG_DRAFT, draft)

        # Stream the regenerated draft to the user in small chunks for better UX
        draft_msg = cl.Message(content="", author="BlogGenerator")
        await draft_msg.send()
        # send progressively in small groups of characters
        chunk_size = 8
        for i in range(0, len(draft), chunk_size):
            part = draft[i : i + chunk_size]
            await draft_msg.stream_token(part)
        await draft_msg.update()
        # send token summary if available
        try:
            from src.tokens import format_usage_summary
            from chainlit.element import Text
            from chainlit.sidebar import ElementSidebar

            token_summary = format_usage_summary(session_id)
            sidebar_text = Text(content=f"ğŸ“Š **ì„¸ì…˜ í† í° ì‚¬ìš©ëŸ‰**\n\n---\n\n{token_summary}")
            await ElementSidebar.set_title("Session Tokens")
            await ElementSidebar.set_elements([sidebar_text])
        except Exception:
            pass