# 05_DATA_CONTEXT.md: 데이터 명세서

이 문서는 RAG 기반 블로그 포스트 생성 시스템의 지식 베이스로 사용되는 데이터의 출처, 특성, 그리고 전처리 과정을 상세히 기술합니다.

---

## 📂 데이터 개요 (Data Overview)

-   **주요 목표**: 본 지식 베이스는 검색 증강 생성(RAG) 및 최신 LLM 아키텍처에 대한 깊이 있는 기술적 내용을 다루는 것을 목표로 합니다.
-   **데이터 유형**: `PDF` 형식의 강의 자료와, AI와의 대화 및 온라인 아티클에서 수집한 `Markdown/Text` 형식의 비정형 텍스트로 구성됩니다.
-   **주요 사용처**: 수집된 데이터는 블로그 포스트 생성을 위한 핵심 컨텍스트를 제공하는 데 사용됩니다.

---

## 📚 소스 상세 분석 (Source Breakdown)

### 📄 PDF 강의 자료

| 파일명 | 출처 | 주요 내용 |
| :--- | :--- | :--- |
| `lecture_01_rag_basics.pdf` | 업스테이지 AI 부트캠프 | RAG 기본 개념, 벡터 DB, 임베딩 모델 |
| `lecture_02_advanced_rag.pdf`| 내부 스터디 그룹 | 리랭킹, 쿼리 변환, 에이전트 기반 RAG |
| `(여기에 다른 PDF 파일 추가)` | | |

### 📝 마크다운 및 텍스트 노트

-   **소스**: 기술 문서, 전문 아티클, 그리고 AI 모델(예: GPT-4)과의 대화에서 얻은 원시 텍스트를 복사하여 수집했습니다.
-   **큐레이션 목표**: 분산된 원시 텍스트 정보들을 "RAG 파이프라인의 실제 구현"이라는 일관된 관점으로 재구성했습니다. 이를 위해 대화형 문답, 중복 예제 등을 제거하여 핵심 정보 위주로 정제했습니다.

---

## ⚙️ 전처리 및 정제 전략 (Preprocessing & Cleaning Strategy)

-   **PDF 추출**: `PyPDFLoader`를 사용하여 PDF 문서를 로드하며, 발표 자료의 구조를 최대한 보존하기 위해 각 슬라이드를 개별 페이지로 분리합니다.

-   **텍스트 정규화**: 수집된 원시 텍스트의 일관성과 품질을 높이기 위해 다음 규칙에 따라 정제 작업을 수행했습니다.
    -   **대화형 표현 제거**: AI 모델과의 대화에서 불필요한 부분("네, 여기 코드가 있습니다...", "도움이 되셨나요?")을 제거했습니다.
    -   **문맥 통합**: 단편적인 문장과 글머리 기호를 완전하고 논리적인 흐름을 갖춘 문단으로 통합했습니다.
    -   **포맷 표준화**: 기술 용어 및 코드 블록의 형식을 일관성 있게 표준화했습니다.

-   **청킹(Chunking) 전략**:
    -   **방법**: `RecursiveCharacterTextSplitter`를 사용하여 문서를 청크로 분할합니다.
    -   **설정**: `chunk_size=1000`, `chunk_overlap=200`으로 설정했습니다. 이는 각 청크가 의미적 맥락을 충분히 유지하면서도, 임베딩 모델(`BAAI/bge-m3`)의 토큰 제한에 최적화된 결과입니다.

---

## ⚠️ 알려진 한계점 (Known Limitations)

-   **잠재적 정보 격차**: 현재 데이터셋은 RAG의 이론적 배경에 강점을 보이나, 실제 프로덕션 환경 수준의 복잡한 코드 예제가 부족합니다.
-   **정보의 최신성**: 온라인 아티클에서 수집한 정보는 2025년 초 기준으로, 일부 라이브러리의 최신 업데이트가 반영되지 않았을 수 있습니다.
