# MODEL_COMPARISON.md
**Date:** August 26, 2025
### 블로그 생성을 위한 오픈소스 LLM 후보

| 모델 | 주요 언어 | 크기 | 최소 VRAM | 권장 VRAM | 출시일 | 주요 특징 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **gpt-oss-20b** | 영어 | 21B | 16 GB | 24 GB | 2025년 8월 | 강력한 추론 능력, 크기 대비 효율적 (MoE). 다용도로 우수. |
| **Llama-3.1-8B-Instruct** | 영어 | 8B | 12 GB | 16 GB | 2025년 7월 | 크기 대비 최고 수준의 성능, 창의적 글쓰기에 탁월. |
| **Mistral-7B-Instruct-v0.3**| 영어 | 7B | 12 GB | 16 GB | 2025년 6월 | 매우 효율적이며 더 큰 모델과 유사한 성능을 보임. |
| **Qwen2-7B-Instruct** | 다국어 (한국어 성능 우수) | 7B | 12 GB | 16 GB | 2025년 6월 | 뛰어난 지시 이행 능력과 강력한 다국어 지원. |
| **gemma-2-9b-it** | 다국어 (한국어 성능 양호) | 9B | 12 GB | 16 GB | 2025년 6월 | 강력한 범용 성능과 우수한 다국어 능력. |
| **SOLAR-10.7B-Instruct** | **한국어** | 10.7B | 12 GB | 16 GB | 2024년 12월 | Upstage가 개발한 한국어 특화 모델. 최고의 선택. |
| **EEVE-Korean-10.8B** | **한국어** | 10.8B | 12 GB | 16 GB | 2025년 3월 | 한국어에 특화된 파인튜닝, 뛰어난 유창성과 문맥 이해. |

---

네, 물론입니다. 임베딩 모델 선택에 대한 중요한 질문들을 주셨네요. 이 부분은 RAG 프로젝트의 성능을 좌우하는 핵심적인 요소입니다.

### 임베딩 모델 선택이 중요한가요?

**네, 매우 중요합니다.** 임베딩 모델은 RAG의 'R' (Retrieval, 검색) 단계를 책임지는 심장과도 같습니다. 모델이 텍스트의 의미를 얼마나 잘 이해하고 벡터로 변환하느냐에 따라, 사용자의 질문이나 주제에 맞는 **정확한 컨텍스트를 찾아내는 능력이 결정**됩니다.

좋은 임베딩 모델을 사용하면 관련성 높은 슬라이드 내용을 가져와 LLM이 양질의 블로그 글을 쓰게 되지만, 성능이 낮은 모델을 사용하면 엉뚱한 내용을 가져와 LLM이 잘못된 정보를 기반으로 글을 쓰게 됩니다.

### 언어가 중요한가요? (한국어)

**네, 언어는 결정적인 차이를 만듭니다.** 임베딩 모델은 특정 언어의 데이터로 학습되어야 해당 언어의 미묘한 의미와 문맥을 이해할 수 있습니다.

* **한국어 특화 모델:** 한국어 데이터로 집중 학습하여 한국어의 고유한 문법, 어휘, 뉘앙스를 잘 파악합니다. 한국어 블로그를 생성하는 것이 주 목적이라면 한국어 특화 모델이나 한국어 성능이 뛰어난 다국어 모델을 사용하는 것이 필수적입니다.
* **영어 기반 모델:** 영어 문서를 처리할 때는 최고의 성능을 보이지만, 한국어 텍스트를 제대로 이해하지 못해 검색 성능이 크게 저하됩니다.

---

### 프로젝트에 적합한 임베딩 모델 후보

프로젝트의 주요 언어에 따라 선택할 수 있는 최고의 오픈소스 모델들을 표로 정리했습니다.

| 모델명 | 주요 언어 | 벡터 차원 | 저장 공간 | 시스템 요구 사항 | 특징 및 장점 |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **bge-m3** | **다국어 (한국어 성능 최상위)** | **1024** | **약 2.3 GB** | **CPU 기반 (GPU 사용 시 속도 향상)** | **현재 가장 강력한 오픈소스 다국어 모델. 100개 이상 언어 지원 및 최대 8192 토큰 처리 가능. 한국어 프로젝트 첫 선택지로 강력 추천.** |
| **ko-sroberta-multitask** | **한국어** | **768** | **약 440 MB** | **CPU 기반 (매우 가벼움)** | **한국어 자연어 처리의 표준 모델. 안정적이며 한국어 데이터에 특화됨.** |
| **intfloat/multilingual-e5-large** | **다국어 (한국어 성능 우수)** | **1024** | **약 2.2 GB** | **CPU 기반 (GPU 사용 시 속도 향상)** | **다양한 언어에서 높은 성능을 보이는 E5 계열 다국어 모델. bge-m3의 훌륭한 대안.** |
| **bge-large-en-v1.5** | **영어** | **1024** | **약 1.3 GB** | **CPU 기반 (GPU 사용 시 속도 향상)** | **영어 전용 콘텐츠를 다룰 때 최고의 선택지 중 하나.** |

---

### 모델 선택 시 고려사항

1.  **성능 (MTEB 점수):** 모델의 성능을 객관적으로 비교하려면 **MTEB (Massive Text Embedding Benchmark)** 리더보드를 확인하는 것이 좋습니다. 특히 한국어 성능(Ko-STS, KLUE 등) 점수가 높은 모델을 선택해야 합니다.
2.  **벡터 차원 (Dimensions):** 모델이 텍스트를 몇 차원의 벡터로 변환하는지를 나타냅니다 (예: 768, 1024). 차원이 높을수록 더 많은 정보를 담을 수 있어 일반적으로 성능이 좋지만, 그만큼 더 많은 저장 공간과 계산 리소스를 필요로 합니다. 현재 시스템 사양(RTX 3090)에서는 1024 차원도 충분히 감당할 수 있습니다.
3.  **범용성:** 대부분의 최신 모델들은 Q&A, 문서 검색 등 다양한 RAG 작업에 모두 좋은 성능을 보입니다. 위에 추천된 모델들은 블로그 생성과 같은 범용적인 작업에 매우 적합합니다.

결론적으로, 한국어 블로그 생성이 목표라면 **`bge-m3`** 모델로 시작하여 프로젝트의 성능을 평가해 보시는 것을 가장 추천합니다.

---
Q: For the embeddings model, what units are the sizes in?
임베딩 모델의 '크기'는 **벡터의 차원(dimensions)**을 의미합니다.

쉽게 말해, 텍스트 조각(예: 슬라이드 내용)의 의미를 표현하기 위해 사용되는 **부동 소수점 숫자의 개수**입니다.

예를 들어, `README`에 언급된 `bge-base-en-v1.5` 모델은 1024차원 모델입니다. 이는 텍스트 한 조각을 1024개의 숫자 리스트(벡터)로 변환하여 그 의미를 좌표처럼 표현한다는 뜻입니다.

차원이 높을수록 더 미묘하고 복잡한 의미를 담을 수 있지만, 그만큼 더 많은 저장 공간과 계산 리소스를 필요로 합니다.

