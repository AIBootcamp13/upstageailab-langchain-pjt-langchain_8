
# configs/config.yaml

# ================================================================================
# RAG 시스템 설정 파일 (RAG System Configuration)
# ================================================================================
# ENV_PROFILE 환경 변수를 통해 활성 프로필을 선택합니다. (예: ENV_PROFILE=high_gpu)

# --- 환경 프로필 (Environment Profiles) ---
# 개발 환경(CPU vs GPU)에 따라 다른 모델 설정을 불러옵니다.
profiles:
  # 기본 프로필: 고성능 GPU가 없는 환경을 위한 설정
  default_cpu:
    # OpenAI API를 사용하는 API 기반 모델
    embedding_provider: "openai"
    embedding_model: "text-embedding-3-large"
    llm_provider: "openai"
    llm_model: "gpt-4o-mini"

  # 고성능 프로필: 강력한 GPU가 있는 환경을 위한 설정
  high_gpu:
    # 로컬에서 실행되는 오픈소스 모델
    embedding_provider: "huggingface"
    embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
    llm_provider: "ollama"
    llm_model: "llama3.1:8b"

# --- 애플리케이션 기본 설정 (Application Settings) ---
app:
  # 시간대 설정
  timezone: "Asia/Seoul"
  # 프로젝트 루트 마커 파일
  root_marker: "pyproject.toml"
  # 기본 환경 프로필
  default_profile: "default_cpu"
  
  # 디렉토리 설정
  directories:
    logs: "logs"
    data: "data"

# --- 데이터 수집 및 처리 (Data Ingestion & Processing) ---
ingestion:
  # PDF 파서 선택: "local", "api", "unstructured"
  parser: "local"

  # 텍스트 분할 설정
  text_splitter:
    chunk_size: 1024
    chunk_overlap: 256

  # Upstage API 로더 설정
  api_loader:
    split: "page"
    output_format: "markdown"

# --- 벡터 저장소 (Vector Store) ---
vector_store:
  # 컬렉션 이름
  collection_name: "lecture_documents"
  
  # 영속성 디렉토리 설정
  # 벡터 데이터가 저장되어 앱 재시작 시 재사용됩니다.
  persist_directory: "db/chroma"
  
  # 검색 설정
  search_type: "mmr"  # "mmr" 또는 "similarity"
  search_kwargs:
    k: 5

# --- 에이전트 시스템 (Agent System) ---
agent:
  # Tavily 웹 검색 도구 설정
  tavily:
    # 검색 결과 최대 개수
    max_results: 3
    # 쿼리 캐시 유사도 임계값
    similarity_threshold: 0.9

  # 문서 검색 도구 설정
  retriever_tool:
    name: "document_search"
    description: "업로드된 PDF 문서에서 정보를 검색하고 반환합니다. 문서 내용에 대한 질문에 답할 때 사용하세요."
  
  # 대화 기록 관리
  max_history_messages: 50
  history_token_limit: 3000
  history_strategy: "compress"  # "truncate" 또는 "compress"
  
  # LLM 생성 설정
  llm:
    max_tokens: 512

# --- 기본값 설정 (Default Values) ---
# 프로필에서 명시되지 않은 경우 사용될 기본값들
defaults:
  # 텍스트 분할 기본값
  text_splitter:
    chunk_size: 1024
    chunk_overlap: 256

  # 벡터 저장소 기본값
  vector_store:
    collection_name: "default_collection"
    search_type: "similarity"
    search_kwargs:
      k: 5

  # 에이전트 기본값
  agent:
    tavily:
      max_results: 3
      similarity_threshold: 0.9
    retriever_tool:
      name: "document_search"
      description: "Document retriever tool"
    max_history_messages: 50
    history_token_limit: 3000
    history_strategy: "truncate"
    llm:
      max_tokens: null

# ================================================================================
# 개발 참고사항 (Development Notes)
# ================================================================================
# 
# 필요한 의존성 (pyproject.toml에 추가):
# - pyyaml
# - pymupdf
# - langchain-huggingface
# - sentence-transformers
# - langchain-upstage
#
# 빠른 디버그 명령어:
# pkill -f 'streamlit run' || true; sleep 1; poetry run streamlit run